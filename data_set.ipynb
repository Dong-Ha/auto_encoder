{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "normal = pd.read_csv(\"C:/Users/tlseh/Desktop/WADI_14days_new.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "normal_drop = normal.drop(['Row','Date','Time'],axis='columns')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "normal_drop_1 = normal_drop[0:1000] # 앞에 1000개만 우선 해보기 위해서 부분 선택\r\n",
    "normal_drop_1 = normal_drop_1.dropna(axis=1) # 값이 없는 열 제거 여기서는 행 4개가 제거되었다."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "normal_drop_1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     1_AIT_001_PV  1_AIT_002_PV  1_AIT_003_PV  1_AIT_004_PV  1_AIT_005_PV  \\\n",
       "0         171.155      0.619473       11.5759       504.645      0.318319   \n",
       "1         171.155      0.619473       11.5759       504.645      0.318319   \n",
       "2         171.155      0.619473       11.5759       504.645      0.318319   \n",
       "3         171.155      0.607477       11.5725       504.673      0.318438   \n",
       "4         171.155      0.607477       11.5725       504.673      0.318438   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "995       174.938      0.559481       11.7524       484.411      0.286654   \n",
       "996       174.938      0.559481       11.7524       484.411      0.286654   \n",
       "997       174.938      0.559481       11.7524       484.411      0.286654   \n",
       "998       174.213      0.541483       11.7854       482.401      0.286422   \n",
       "999       174.213      0.541483       11.7854       482.401      0.286422   \n",
       "\n",
       "     1_FIT_001_PV  1_LS_001_AL  1_LS_002_AL  1_LT_001_PV  1_MV_001_STATUS  \\\n",
       "0        0.001157            0            0      47.8911                1   \n",
       "1        0.001157            0            0      47.8911                1   \n",
       "2        0.001157            0            0      47.8911                1   \n",
       "3        0.001207            0            0      47.7503                1   \n",
       "4        0.001207            0            0      47.7503                1   \n",
       "..            ...          ...          ...          ...              ...   \n",
       "995      1.907730            0            0      40.5656                2   \n",
       "996      1.907730            0            0      40.5656                2   \n",
       "997      1.907730            0            0      40.5656                2   \n",
       "998      2.003600            0            0      40.8926                2   \n",
       "999      2.003600            0            0      40.8926                2   \n",
       "\n",
       "     ...  3_MV_001_STATUS  3_MV_002_STATUS  3_MV_003_STATUS  3_P_001_STATUS  \\\n",
       "0    ...                1                1                1               1   \n",
       "1    ...                1                1                1               1   \n",
       "2    ...                1                1                1               1   \n",
       "3    ...                1                1                1               1   \n",
       "4    ...                1                1                1               1   \n",
       "..   ...              ...              ...              ...             ...   \n",
       "995  ...                1                1                1               1   \n",
       "996  ...                1                1                1               1   \n",
       "997  ...                1                1                1               1   \n",
       "998  ...                1                1                1               1   \n",
       "999  ...                1                1                1               1   \n",
       "\n",
       "     3_P_002_STATUS  3_P_003_STATUS  3_P_004_STATUS  LEAK_DIFF_PRESSURE  \\\n",
       "0                 1               1               1             67.9651   \n",
       "1                 1               1               1             67.9651   \n",
       "2                 1               1               1             67.9651   \n",
       "3                 1               1               1             67.1948   \n",
       "4                 1               1               1             67.1948   \n",
       "..              ...             ...             ...                 ...   \n",
       "995               1               1               1             63.8467   \n",
       "996               1               1               1             63.8467   \n",
       "997               1               1               1             63.8467   \n",
       "998               1               1               1             63.9204   \n",
       "999               1               1               1             63.9204   \n",
       "\n",
       "     PLANT_START_STOP_LOG  TOTAL_CONS_REQUIRED_FLOW  \n",
       "0                       1                      0.68  \n",
       "1                       1                      0.68  \n",
       "2                       1                      0.68  \n",
       "3                       1                      0.68  \n",
       "4                       1                      0.68  \n",
       "..                    ...                       ...  \n",
       "995                     1                      0.68  \n",
       "996                     1                      0.68  \n",
       "997                     1                      0.68  \n",
       "998                     1                      0.68  \n",
       "999                     1                      0.68  \n",
       "\n",
       "[1000 rows x 123 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_AIT_001_PV</th>\n",
       "      <th>1_AIT_002_PV</th>\n",
       "      <th>1_AIT_003_PV</th>\n",
       "      <th>1_AIT_004_PV</th>\n",
       "      <th>1_AIT_005_PV</th>\n",
       "      <th>1_FIT_001_PV</th>\n",
       "      <th>1_LS_001_AL</th>\n",
       "      <th>1_LS_002_AL</th>\n",
       "      <th>1_LT_001_PV</th>\n",
       "      <th>1_MV_001_STATUS</th>\n",
       "      <th>...</th>\n",
       "      <th>3_MV_001_STATUS</th>\n",
       "      <th>3_MV_002_STATUS</th>\n",
       "      <th>3_MV_003_STATUS</th>\n",
       "      <th>3_P_001_STATUS</th>\n",
       "      <th>3_P_002_STATUS</th>\n",
       "      <th>3_P_003_STATUS</th>\n",
       "      <th>3_P_004_STATUS</th>\n",
       "      <th>LEAK_DIFF_PRESSURE</th>\n",
       "      <th>PLANT_START_STOP_LOG</th>\n",
       "      <th>TOTAL_CONS_REQUIRED_FLOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171.155</td>\n",
       "      <td>0.619473</td>\n",
       "      <td>11.5759</td>\n",
       "      <td>504.645</td>\n",
       "      <td>0.318319</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.8911</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67.9651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171.155</td>\n",
       "      <td>0.619473</td>\n",
       "      <td>11.5759</td>\n",
       "      <td>504.645</td>\n",
       "      <td>0.318319</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.8911</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67.9651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171.155</td>\n",
       "      <td>0.619473</td>\n",
       "      <td>11.5759</td>\n",
       "      <td>504.645</td>\n",
       "      <td>0.318319</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.8911</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67.9651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171.155</td>\n",
       "      <td>0.607477</td>\n",
       "      <td>11.5725</td>\n",
       "      <td>504.673</td>\n",
       "      <td>0.318438</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.7503</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67.1948</td>\n",
       "      <td>1</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171.155</td>\n",
       "      <td>0.607477</td>\n",
       "      <td>11.5725</td>\n",
       "      <td>504.673</td>\n",
       "      <td>0.318438</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.7503</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67.1948</td>\n",
       "      <td>1</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>174.938</td>\n",
       "      <td>0.559481</td>\n",
       "      <td>11.7524</td>\n",
       "      <td>484.411</td>\n",
       "      <td>0.286654</td>\n",
       "      <td>1.907730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.5656</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63.8467</td>\n",
       "      <td>1</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>174.938</td>\n",
       "      <td>0.559481</td>\n",
       "      <td>11.7524</td>\n",
       "      <td>484.411</td>\n",
       "      <td>0.286654</td>\n",
       "      <td>1.907730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.5656</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63.8467</td>\n",
       "      <td>1</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>174.938</td>\n",
       "      <td>0.559481</td>\n",
       "      <td>11.7524</td>\n",
       "      <td>484.411</td>\n",
       "      <td>0.286654</td>\n",
       "      <td>1.907730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.5656</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63.8467</td>\n",
       "      <td>1</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>174.213</td>\n",
       "      <td>0.541483</td>\n",
       "      <td>11.7854</td>\n",
       "      <td>482.401</td>\n",
       "      <td>0.286422</td>\n",
       "      <td>2.003600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.8926</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63.9204</td>\n",
       "      <td>1</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>174.213</td>\n",
       "      <td>0.541483</td>\n",
       "      <td>11.7854</td>\n",
       "      <td>482.401</td>\n",
       "      <td>0.286422</td>\n",
       "      <td>2.003600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.8926</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63.9204</td>\n",
       "      <td>1</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 123 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "normal_drop_1.isnull().sum().sum() # 성분에서 NaN이 있으면 1이상의 값이 나오게 된다. pd.DataFrame.isnull().sum().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from sklearn import preprocessing       # 정규화를 반드시 진행해야 하는 건지?\r\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\r\n",
    "\r\n",
    "x = normal_drop_1.values\r\n",
    "x_scaled = min_max_scaler.fit_transform(x)\r\n",
    "normal_drop_1_scaled = pd.DataFrame(x_scaled)\r\n",
    "\r\n",
    "print(normal_drop_1_scaled)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          0         1         2         3         4         5    6    7    \\\n",
      "0    0.006593  0.529401  0.252453  0.919934  0.824437  0.000094  0.0  0.0   \n",
      "1    0.006593  0.529401  0.252453  0.919934  0.824437  0.000094  0.0  0.0   \n",
      "2    0.006593  0.529401  0.252453  0.919934  0.824437  0.000094  0.0  0.0   \n",
      "3    0.006593  0.470590  0.240948  0.921092  0.827501  0.000118  0.0  0.0   \n",
      "4    0.006593  0.470590  0.240948  0.921092  0.827501  0.000118  0.0  0.0   \n",
      "..        ...       ...       ...       ...       ...       ...  ...  ...   \n",
      "995  0.662908  0.235287  0.849746  0.083127  0.009064  0.923259  0.0  0.0   \n",
      "996  0.662908  0.235287  0.849746  0.083127  0.009064  0.923259  0.0  0.0   \n",
      "997  0.662908  0.235287  0.849746  0.083127  0.009064  0.923259  0.0  0.0   \n",
      "998  0.537127  0.147052  0.961421  0.000000  0.003090  0.969679  0.0  0.0   \n",
      "999  0.537127  0.147052  0.961421  0.000000  0.003090  0.969679  0.0  0.0   \n",
      "\n",
      "          8    9    ...  113  114  115  116  117  118  119       120  121  122  \n",
      "0    0.779419  0.5  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.102249  0.0  0.0  \n",
      "1    0.779419  0.5  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.102249  0.0  0.0  \n",
      "2    0.779419  0.5  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.102249  0.0  0.0  \n",
      "3    0.765998  0.5  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.092489  0.0  0.0  \n",
      "4    0.765998  0.5  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.092489  0.0  0.0  \n",
      "..        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...  ...  ...  \n",
      "995  0.081121  1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.050069  0.0  0.0  \n",
      "996  0.081121  1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.050069  0.0  0.0  \n",
      "997  0.081121  1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.050069  0.0  0.0  \n",
      "998  0.112292  1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.051003  0.0  0.0  \n",
      "999  0.112292  1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.051003  0.0  0.0  \n",
      "\n",
      "[1000 rows x 123 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "normal_drop_1 = np.array(normal_drop_1).astype('float') # Dataframe을 numpy로 변환"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "normal_drop_1.shape\r\n",
    "print(\"before transpose :{}\".format(normal_drop_1.shape)) # 데이터셋 입력전 rnn 모양을 맞춰주기 위해서 행열 transpose\r\n",
    "normal_drop_1 = np.transpose(normal_drop_1)\r\n",
    "print(\"after transpose :{}\".format(normal_drop_1.shape))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "before transpose :(1000, 123)\n",
      "after transpose :(123, 1000)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "normal_drop_1 = torch.from_numpy(normal_drop_1).unsqueeze(0) # 배치 차원을 추가 해주기 위해서 첫번째 위치에 차원 추가"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "normal_drop_1.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 123, 1000])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def Window(data,window,step):   # window 구현을 어떻게 해야 할지 몰라서 함수로 구현\r\n",
    "    batch_size = (data.shape[-1] - window) // step\r\n",
    "    Window_complete = torch.tensor([])\r\n",
    "\r\n",
    "    for index in range(batch_size):\r\n",
    "        x = torch.clone(data[:,:, step * index : window + step * index])\r\n",
    "        Window_complete = torch.cat((Window_complete,x),dim=0)\r\n",
    "\r\n",
    "    return Window_complete "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "data = Window(normal_drop_1,window=5,step=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([331, 123, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from torch.utils.data import Dataset\r\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "class CustomDataset(Dataset):   # 데이터셋에 굳이 넣어야 하는건지?\r\n",
    "  def __init__(self,data):\r\n",
    "      self.data = data\r\n",
    "\r\n",
    "  def __getitem__(self, idx): \r\n",
    "    return self.data[idx]\r\n",
    "\r\n",
    "  def __len__(self): \r\n",
    "    return len(self.data)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "dataset = CustomDataset(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "INPUT_SIZE = dataset.data.shape[-1]\r\n",
    "SEQ_LEN = dataset.data.shape[-2]\r\n",
    "BATCH_SIZE = 3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "type(INPUT_SIZE)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "dataloader = DataLoader(dataset,batch_size=BATCH_SIZE, shuffle=False,drop_last=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "from torch import nn, optim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "class Encoder(nn.Module):\r\n",
    "    def __init__(self, input_size, embedding_dim=32):\r\n",
    "        super(Encoder, self).__init__()\r\n",
    "\r\n",
    "        self.input_size = input_size\r\n",
    "        self.hidden_dim = embedding_dim * 2\r\n",
    "        self.embedding_dim = embedding_dim \r\n",
    "\r\n",
    "        \r\n",
    "        self.rnn1 = nn.LSTM(input_size=self.input_size,hidden_size=self.hidden_dim,num_layers=1,batch_first=True)\r\n",
    "        self.rnn2 = nn.LSTM(input_size=self.hidden_dim,hidden_size=self.embedding_dim,num_layers=1,batch_first=True)\r\n",
    "\r\n",
    "    def forward(self, x):           # (batch size, 123, window)\r\n",
    "        x = x.float()\r\n",
    "        x,(_,_) = self.rnn1(x)\r\n",
    "        x, (hidden,cell) = self.rnn2(x) # (batch size, 123, embedding_dim)\r\n",
    "\r\n",
    "        return hidden"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "class Decoder(nn.Module):\r\n",
    "    def __init__(self,input_size=32, output_size=INPUT_SIZE):\r\n",
    "        super(Decoder, self).__init__()\r\n",
    "\r\n",
    "        self.input_size = input_size\r\n",
    "        self.hidden_dim = input_size * 2\r\n",
    "        self.output_size = output_size\r\n",
    "\r\n",
    "        self.rnn1 = nn.LSTM(input_size=self.input_size,hidden_size=self.hidden_dim,batch_first=True)\r\n",
    "        self.rnn2 = nn.LSTM(input_size=self.hidden_dim,hidden_size=self.output_size,batch_first=True)\r\n",
    "\r\n",
    "    def forward(self,x):\r\n",
    "        x = x.permute(1,0,2)\r\n",
    "        x = x.repeat(1,SEQ_LEN,1)\r\n",
    "        x,(_,_) = self.rnn1(x)\r\n",
    "        x,(_,_) = self.rnn2(x)\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "class Autoencoder(nn.Module):\r\n",
    "\r\n",
    "  def __init__(self,input_size,output_size, embedding_dim=64):\r\n",
    "    super(Autoencoder, self).__init__()\r\n",
    "\r\n",
    "    self.encoder = Encoder(input_size, embedding_dim=32)\r\n",
    "    self.decoder = Decoder(input_size=32, output_size=INPUT_SIZE)\r\n",
    "\r\n",
    "  def forward(self, x):\r\n",
    "    x = self.encoder(x)\r\n",
    "    x = self.decoder(x)\r\n",
    "\r\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "model = Autoencoder(5,1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "#criterion = nn.CrossEntropyLoss()\r\n",
    "criterion = nn.L1Loss(reduction='sum')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "for i, batch in enumerate(dataloader):\r\n",
    "        \r\n",
    "    optimizer.zero_grad()\r\n",
    "    \r\n",
    "    output = model(batch)\r\n",
    "    \r\n",
    "    loss = criterion(output, batch)\r\n",
    "    \r\n",
    "    loss.backward()\r\n",
    "\r\n",
    "    if i % 10 == 0:\r\n",
    "        print(\"NOW index : {}, LOSS : {}\".format(i, loss))\r\n",
    "\r\n",
    "    optimizer.step()\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NOW index : 0, LOSS : 82319.6015625\n",
      "NOW index : 10, LOSS : 85268.0\n",
      "NOW index : 20, LOSS : 86746.140625\n",
      "NOW index : 30, LOSS : 87032.453125\n",
      "NOW index : 40, LOSS : 86911.234375\n",
      "NOW index : 50, LOSS : 86618.75\n",
      "NOW index : 60, LOSS : 86228.875\n",
      "NOW index : 70, LOSS : 62145.953125\n",
      "NOW index : 80, LOSS : 84153.3828125\n",
      "NOW index : 90, LOSS : 85851.640625\n",
      "NOW index : 100, LOSS : 85959.5625\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "for i, batch in enumerate(dataloader):\r\n",
    "    print(i)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "xxx = 0\r\n",
    "x = 0\r\n",
    "model = Encoder(5)\r\n",
    "for i,dom in enumerate(dataloader):\r\n",
    "    x = model(dom)\r\n",
    "\r\n",
    "    xxx += 1\r\n",
    "    if xxx ==1:\r\n",
    "        break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "dom.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 123, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "x.permute(1,0,2).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 32])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "modu = Decoder()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "x_final = modu(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "x_final.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 123, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "aaa = Autoencoder(5,1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "fffff = aaa(dom)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "fffff.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 123, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('lab': conda)"
  },
  "interpreter": {
   "hash": "d0bda0206111b919826ea007f7bf17d966c84c6481f60aa426c1e7f2ea1ecded"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}